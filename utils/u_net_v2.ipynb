{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã„nderungen, die im Vergleich zum zuerst verwendeten Netzwerk gemacht wurden:\n",
    "\n",
    "- **Anzahl der Layers**\n",
    "1. Erste Schicht - 16 -> 32\n",
    "2. Zweite Schicht - 32 -> 64\n",
    "3. Dritte Schicht - 64 -> 128\n",
    "4. Vierte Schicht - neue Schicht mit 256x256 Filter\n",
    "\n",
    "- **Batch Normalization**\n",
    "\n",
    "- **Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:05:49.754116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749564349.774477 3253954 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749564349.780488 3253954 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749564349.797906 3253954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749564349.797943 3253954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749564349.797945 3253954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749564349.797947 3253954 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-10 14:05:49.803110: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryIoU, Precision, Recall\n",
    "\n",
    "def unet_model(input_size, dropout_rate=0.2):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder with BatchNorm and Dropout\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)  # Increased from 16\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout_rate)(p1)\n",
    "    \n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)  # Increased from 32\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout_rate)(p2)\n",
    "    \n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)  # Increased from 64\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout_rate)(p3)\n",
    "    \n",
    "    # Deeper encoder for better feature extraction\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout_rate)(p4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same')(p4)  # Increased from 128\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Dropout(dropout_rate * 1.5)(c5)  # Higher dropout in bottleneck\n",
    "    \n",
    "    # Decoder\n",
    "    u1 = UpSampling2D((2, 2))(c5)\n",
    "    u1 = Concatenate()([u1, c4])\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', padding='same')(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Dropout(dropout_rate)(c6)\n",
    "    \n",
    "    u2 = UpSampling2D((2, 2))(c6)\n",
    "    u2 = Concatenate()([u2, c3])\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', padding='same')(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Dropout(dropout_rate)(c7)\n",
    "    \n",
    "    u3 = UpSampling2D((2, 2))(c7)\n",
    "    u3 = Concatenate()([u3, c2])\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', padding='same')(u3)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', padding='same')(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Dropout(dropout_rate)(c8)\n",
    "    \n",
    "    u4 = UpSampling2D((2, 2))(c8)\n",
    "    u4 = Concatenate()([u4, c1])\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', padding='same')(u4)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', padding='same')(c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ergebnisse:\n",
    "- das Model scheint nicht viel Besser als das Originale zu sein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# # def unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "# def unet_model(input_size, dropout_rate=0.2):\n",
    "#   inputs = Input(input_size)\n",
    "\n",
    "#   # Encoder\n",
    "#   c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#   c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n",
    "#   p1 = MaxPooling2D((2, 2))(c1)\n",
    "#   p1 = Dropout(dropout_rate)(p1)\n",
    "\n",
    "#   c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
    "#   c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n",
    "#   p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "#   c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
    "#   c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(c3)\n",
    "#   p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "#   # Bottleneck\n",
    "#   c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
    "#   c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "#   # Decoder\n",
    "#   u1 = UpSampling2D((2, 2))(c4)\n",
    "#   u1 = Concatenate()([u1, c3])\n",
    "#   c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "#   c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "#   u2 = UpSampling2D((2, 2))(c5)\n",
    "#   u2 = Concatenate()([u2, c2])\n",
    "#   c6 = Conv2D(32, (3, 3), activation='relu', padding='same')(u2)\n",
    "#   c6 = Conv2D(32, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "#   u3 = UpSampling2D((2, 2))(c6)\n",
    "#   u3 = Concatenate()([u3, c1])\n",
    "#   c7 = Conv2D(16, (3, 3), activation='relu', padding='same')(u3)\n",
    "#   c7 = Conv2D(16, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "#   outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "#   model = Model(inputs, outputs)\n",
    "#   return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
